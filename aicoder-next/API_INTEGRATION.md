# AI Code Improver - API Integration Guide

## Overview

The AI Code Improver Pro application is now **fully integrated** with multiple AI providers. All features are working seamlessly with real AI API calls.

## Supported AI Providers

### 1. **OpenAI** (GPT Models)

- **Models**: GPT-4o, GPT-4o-mini, GPT-4-turbo, GPT-3.5-turbo
- **API Key Required**: Yes
- **Get API Key**: https://platform.openai.com/api-keys
- **Cost**: Pay per token usage

### 2. **Anthropic** (Claude Models)

- **Models**: Claude 3.5 Sonnet, Claude 3 Opus, Claude 3 Sonnet, Claude 3 Haiku
- **API Key Required**: Yes
- **Get API Key**: https://console.anthropic.com/
- **Cost**: Pay per token usage

### 3. **Google** (Gemini Models)

- **Models**: Gemini Pro, Gemini Pro Vision
- **API Key Required**: Yes
- **Get API Key**: https://makersuite.google.com/app/apikey
- **Cost**: Free tier available

### 4. **Ollama** (Local Models)

- **Models**: Llama 3.1, CodeLlama, Mistral, DeepSeek-Coder
- **API Key Required**: No
- **Setup**: Install Ollama locally from https://ollama.ai
- **Cost**: Free (runs on your machine)

## Features

### Code Improvement Modes

1. **Error Repair** ðŸ”§ - Fix bugs and add error handling
2. **Visual Enhancement** âœ¨ - Improve code readability
3. **Optimize** âš¡ - Enhance performance and efficiency
4. **Document** ðŸ“š - Add comprehensive documentation
5. **Security** ðŸ”’ - Fix security vulnerabilities
6. **Test** ðŸ§ª - Generate unit tests
7. **Convert** ðŸ”„ - Modernize code
8. **Explain** ðŸ’¡ - Explain code functionality
9. **Natural Language to Code** ðŸ’¬ - Convert descriptions to code

## How to Use

### Step 1: Configure Settings

1. Click the **Settings** button in the header
2. Select your preferred **AI Provider**
3. Choose an **AI Model**
4. Enter your **API Key** (not required for Ollama)
5. Click **Save Settings**

### Step 2: Improve Code

1. Paste or type your code in the input area
2. Select an **Improvement Mode**
3. Click **Improve Code**
4. Wait for AI to process (usually 2-10 seconds)
5. View the improved code in the output panel

### Step 3: Use Improved Code

1. Click **Copy** to copy the improved code to clipboard
2. Or manually select and copy the code
3. Use the improved code in your projects!

## API Integration Details

### Architecture

```
Frontend (MainInterface.tsx)
    â†“
API Route (/api/improve/route.ts)
    â†“
Provider-specific API call
    â†“
Response processing
    â†“
Frontend displays result
```

### Security

- **API keys are stored locally** in the browser's localStorage
- **Keys are never sent to our servers** (only to official AI provider APIs)
- All API calls go through Next.js API routes for better security
- HTTPS encryption for all requests

### Error Handling

The application includes comprehensive error handling:

- Invalid API keys
- Network errors
- Rate limiting
- Empty or invalid input
- Provider-specific errors

## Troubleshooting

### "API key is required" error

Make sure you've entered a valid API key in Settings for your chosen provider.

### "Failed to improve code" error

- Check your internet connection
- Verify your API key is correct
- Ensure you have sufficient credits/quota with the provider
- Try a different model or provider

### Ollama "Connection failed" error

- Make sure Ollama is installed and running on your machine
- Verify the Ollama URL is correct (default: http://localhost:11434)
- Pull the model you want to use: `ollama pull llama3.1`

### Slow response times

- Some models are slower than others
- First request may be slower due to model loading
- Consider using smaller models for faster responses

## Development

### Running Locally

```bash
cd aicoder-next
npm install
npm run dev
```

### Environment Variables (Optional)

Create a `.env.local` file for default configurations:

```env
NEXT_PUBLIC_DEFAULT_PROVIDER=openai
NEXT_PUBLIC_DEFAULT_MODEL=gpt-4o
```

### Adding a New Provider

1. Add provider to `providerModels` in `MainInterface.tsx`
2. Implement API call function in `/api/improve/route.ts`
3. Add case in switch statement
4. Update UI if needed

## API Rate Limits

| Provider      | Free Tier   | Rate Limits        |
| ------------- | ----------- | ------------------ |
| OpenAI        | No          | Varies by plan     |
| Anthropic     | No          | Varies by plan     |
| Google Gemini | Yes         | 60 requests/minute |
| Ollama        | Yes (Local) | No limits          |

## Best Practices

1. **Start with smaller models** for testing
2. **Use Ollama for unlimited testing** locally
3. **Monitor your API usage** with providers
4. **Keep API keys secure** and don't share them
5. **Use appropriate modes** for your needs

## Support

For issues or questions:

- Check the error message in the notification
- Review your browser console for detailed errors
- Verify provider-specific documentation
- Ensure all dependencies are installed

## Future Enhancements

Planned features:

- âœ… Full AI provider integration (DONE)
- âœ… Multiple improvement modes (DONE)
- âœ… Real-time notifications (DONE)
- ðŸ”„ Code diff view
- ðŸ”„ History with local storage
- ðŸ”„ Export functionality
- ðŸ”„ Batch processing
- ðŸ”„ Custom prompts

---

**Note**: The application is now fully functional with real AI integration. No placeholder messages - all features work as expected!
